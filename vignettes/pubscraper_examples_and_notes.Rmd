---
title: "pubscraper_examples_and_notes"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{pubscraper_examples_and_notes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


# Introduction

The `pubscraper` package is a helper and a wrapper for `businessPubMed` which extracts author information from PubMed query results for a user-defined set of search terms. The `scrape2csv` function was written for the purpose of automating the process of querying the same set of search terms over a defined list of journals to extract author contact information and produce a list with unduplicated contacts. However, the `scrape2csv` function can be used for PubMed queries over all journals and can be used to produce csv files other than author contact information. 

Query results from all journals (if defined) are compiled, cleaned of duplicates in regards to author contact information (name and email), and then exported to csv. As a default, raw query results for each journal are also exported to csv and a report of several different types of counts of unique observations (journal, article, author, email, and contact information) are provided and exported to csv.  

## Installing the pubscraper package

The `pubscraper` package can be installed from GitHub via devtools package (`devtools` package is available on CRAN). It requires easyPubMed and businessPubMed (available on GitHub) for performing the queries, and dplyr. Tidyverse is suggested.


```{r install, include=T, eval=F}
## tidyverse is suggested since functions from dplyr and tidyr are used
# install.packages("tidyverse") 
# install.pacakges("here")
# install.packages("devtools")
devtools::install_github("dami82/easyPubMed")
devtools::install_github("dami82/businessPubMed")
devtools::install_github("biostatistically/pubscraper")
```

```{r setup, include=T, eval=T}
library(tidyverse)
library(easyPubMed)
library(businessPubMed)
library(here)
library(pubscraper)
```

# Basics

## The arguments

Here's the structure of the entire function. There are a lot of options to customize your search and output, but only two of the parameters are required for you to define: `narrow` (the search terms) and `start` (the start of the range of dates for PubMed to search).
```{r eval=F}
scrape2csv <- function(narrow, 
                       broad=NULL,
                       operator=NULL,
                       journals=NULL, 
                       start, 
                       end=NULL, 
                       title=NULL, 
                       outpath=NULL, 
                       newfolder=TRUE, 
                       raw=TRUE,
                       clist=TRUE,
                       alist=FALSE,
                       plist=FALSE,
                       jlist=FALSE,
                       report=TRUE)
```

More details:

*  `narrow` : ( __REQUIRED__; character vector of length 1) This parameter has a lot of flexibility. One way to use this argument is for key search terms using AND as the operator between terms (therefore the parameter name of `narrow`). Each term must be enclosed in double quotes, and the whole set of terms needs to be enclosed in parentheses. e.g. ("keyword" AND "some key phrase" AND "another key phrase") _NOTE- for advanced users, this parameter can be used to enter all desired search terms with any Boolean operator(s)._
*  `broad` : (optional; character vector of length 1) Again, there is flexibility of how this is defined. In the same vein as above, one way to use this is for key search terms using OR as the operator between terms. e.g. ("keyword1" OR "key phrase1") 
*  `operator` : (optional; character string) Boolean operator to be placed between `narrow` and `broad`; if not specified, 'AND' will be used
*  `journals` : (optional; character vector of length j) a list of journals to query for the set of search terms. _Note- When specified, the query will iterate over the list of journals for the set of search terms defined
*  `start` : ( __REQUIRED__; character string) the earliest publication date you want to search
*  `end` : (optional) the latest publication date you want to search; if not specified, default of 3000/12/31 will be used
*  `title` : (optional; character string) title of your query which will be used to name folders and output files NOTE- best to keep it short and simple
*  `outpath` : (optional; character string) directory where you want your output to be placed; if not specified, the working directory will be used
*  `newfolder` : If TRUE, a new folder will be created for your output; default is TRUE
*  `raw` : If TRUE, raw query results are exported to csv; default is TRUE
*  `clist` : If TRUE, author contact information with emails will be exported to csv; default is TRUE
*  `alist` : If TRUE, a list of authors with a count of articles and a count of journals for each author is exported to csv; default is FALSE
*  `plist` : If TRUE, a list of articles with journal and first author name is exported to csv; default is FALSE
*  `jlist` = If TRUE, a list of journals with a count of number of articles is exported to csv; default is FALSE
*  `report` = If TRUE, a query report will be exported to csv; default is TRUE


## Example

Let's say we want to know what journals have published articles on the effect of social media on mental health in adolescents in 2020. We'd also like to know how many articles each journal has published on the subject. In addition, we want a list of publication titles with their first authors. We can set up our query by:

* using ("social media" AND "adolescents") in the `narrow` search term parameter. *(It's narrow since you're meant to put AND between each search term. There is flexibility in this, however. See the next section on customizing the query even further.)*
* using ("mental health" OR "mental illness") in the `broad` search term parameter to give a little more leeway to this aspect. *(It's broad since you're meant to put OR between each search term. This parameter is optional.)*
* using "AND" for the operator between `narrow` and `broad`
* setting the start date to 2020/01/01 (or 2020/01)

The resulting query will be __("social media" AND "adolescents") AND ("mental health" OR "mental illness")__ for articles published from 2020/01/01 to 3000/12/31 (since `start = "2020/01/01"` and `end = NULL`). _The end date is not a typo - 3000/12/31 is the default end of publication date range in PubMed. _Note- This can result in queries containing articles that have a published date in the future. So if you want only want articles that have a publication date in 2020, then `end = "2020/12/31"` needs to be specified._ 

If a `title` is defined, output files will be created with the prefix specified for title. In this case `title = "SocialMedia_run01"`. Note: Best to keep titles as simple as possible since they go into file nomenclature.

Since we want a list of journals with a count of publications matching search criteria for each journal, we specify `jlist = TRUE`. We also specify `plist = TRUE`, since we want a separate list of publication titles. 

If we go with the defaults of `raw = TRUE`, `report = TRUE`, we will obtain raw results and a query report as csv files. If `newfolder = FALSE`, the csv files are exported to the working directory. In the example below, we will obtain the following csv files:

* raw query search results of journals, publication titles, authors, author affiliation, author email (since `raw = TRUE` when not defined by the user)
* a list of journals with the total number of publication titles appearing in the search for each journal (since `jlist = TRUE`)
* publication list with title, journal, year, as well as first author first name and last name (since default is `plist = TRUE`)
* a report of query stats (since default is `report = TRUE` when not specified by user)
   
```{r run01, include=T, eval=T}
n_terms <- '("social media" AND "adolescents")'
b_terms <- '("mental health" OR " mental illness")'
my.operator <- "AND" #explicitly being specified eventhough AND is the default
my.start <- "2020/01/01"
my.end <- "2020/12/31"
my.title <- "SocialMedia_run01"  

scrape2csv(narrow = n_terms, 
           broad = b_terms, 
           operator = my.operator, 
           start = my.start, 
           end = my.end, 
           title = my.title, 
           newfolder = FALSE, 
           outpath = "/Users/ivy/example", 
           plist = TRUE,
           jlist = TRUE)
```


## Customizing

You can also create a much more customized query. For example, we want to search: **("adolescents" OR "teens" OR "young adults") AND ("social media" AND "mental health") AND ("sleep" OR "depression") NOT ("apnea")** - see *https://pubmed.ncbi.nlm.nih.gov/advanced/*

We would assign this customized query to `narrow` and leave `broad` blank.

In this example we will query two journals, "Sleep Health" and "J Adolesc Health" for these search terms from 2011 through 2020. The query will loop through the list of journals, in the case just 2, iteratively.  

If we don't specify `newfolder = FALSE`, a new folder for the output called 'SocialMedia_run02' will be created (this comes from the title you specify - if `title = NULL`, the new folder will be called 'Untitled'). It's best practice to title your runs differently since files and folders can be overwritten if they have the same name. 

Since `newfolder = TRUE`, the following csv files are exported to a new folder SocialMedia_run02:

* raw query search results of articles, authors, author affiliation, author email __for each specified journal__ (since default is `raw = TRUE`)
* author contact information compiled from both journals, then cleaned of duplicates by author first name, last name, and email (since default is `clist = TRUE`)
* a report of query stats (since default is `report = TRUE`)

```{r run02, include=T, eval=T}
my.custom <- '("adolescents" OR "teens" OR "young adults") AND ("social media" AND "mental health") AND ("sleep" OR "depression") NOT ("apnea")'
my.journals <- c("Sleep Health", "J Adolesc Health")
my.start <- "2011"
my.end <- "2020"
my.title <- "SocialMedia_run02"
scrape2csv(narrow = my.custom, 
           journals = my.journals, 
           start = my.start, 
           end = my.end, 
           title = my.title, 
           outpath = "/Users/ivy/example/")
```